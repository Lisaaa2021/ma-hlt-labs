{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 Assignment: testing classifiers on a different data set with tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build and apply classifiers built in the notebooks of lab3 to another data set with emotion labels which was used in the *Wassa* workshop in 2017:\n",
    "\n",
    "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n",
    "\n",
    "Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark.\n",
    "\n",
    "The texts are tweets and therefore a different genre than the spoken utterances from the conversations in the MELD data set. The data set is included in the distribution of this lab, where we aggregated all the training and test data in a single file. The notebook already includes the code for lading the CSV files in a Pandas dataframe.\n",
    "\n",
    "We also included the functions to get AveragedWordEmbeddings in a separate Python file: **lab3_util.py**. These can be used to create embedding based representations for the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the tweet data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              Tweet  Label  Score\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....  anger  0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...  anger  0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...  anger  0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...  anger  0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...  anger  0.896"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = './data/wassa/training/all.train.tsv'\n",
    "dftweets_train = pd.read_csv(filepath, sep='\\t')\n",
    "dftweets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3613 entries, 0 to 3612\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ID      3613 non-null   int64  \n",
      " 1   Tweet   3613 non-null   object \n",
      " 2   Label   3613 non-null   object \n",
      " 3   Score   3613 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 113.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dftweets_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this data set has 3613 tweets, labels and a score. Lets check the distribution of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE THE GENERATE A BAR CHART FOR THE TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### Test data\n",
    "filepath = './data/wassa/testing/all.test.tsv'\n",
    "dftweets_test = pd.read_csv(filepath, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE THE GENERATE A BAR CHART FOR THE TEST DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANALYSIS OF THE DATA DISTRIBUTION [2 points]\n",
    "\n",
    "HERE COME YOUR COMMENTS ON THE DISTRIBUTION OF THE TRAIN AND TEST DATA AND A COMPARISON WITH THE DISTRIBUTION IN MELD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a classifier with averaged word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the texts and labels for the training and testing [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO EXTRACT THE TRAINING TEXTS AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO EXTRACT THE TEST TEXTS AND LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Representing and classifying tweets as averaged word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Representing the tweet training data using the same word embedding model [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same functions that we used in the notebook *Lab3.6.ml.emotion-detection.embeddings.ipynb* to get averaged embeddings for the tweets. \n",
    "In order to use exactly the same function and to be able to re-use them again, we copied these functions to a separate python file \"lab3_util.py\". You can open the file in Jupyter to inspect its content.\n",
    "\n",
    "We can now import this file as we do with other packages and apply it in this notebook but also in other code. This keeps our notebook readable and compact and makes sure we always use the same functions and do not accidently change them across notebooks.\n",
    "\n",
    "For future coding, it is wise to also apply this to your own code. Put reusable code as functions in a separate Python file with an illegible name and import this in different notebooks or other Python files. In this way, you develop your own tools over time and reuse them when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the Python file *lab3_util.py* in this notebook so that the functions are loaded in working memory. The file should be located in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab3_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point onwards, you can call the functions from this file as follows:\n",
    "\n",
    "* util.getAvgFeatureVecs(.....)\n",
    "* util.getMostFrequentWords(.....)\n",
    "\n",
    "Check the parameters of the functions required to call them and check the return values to catch what they return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to load the same word embedding model as we used before to get compatible word embeddings for this data. Choose whatever you used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO DERIVE AVERAGED WORD EMBEDDING REPRESENTATIONS FOR THE TRAINING DATA\n",
    "# TIP: HERE YOU USE THE CODE FROM LAB3_UTIL.PY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we check which words are not in the embedding model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GET THE LIST OF UNKNOWN WORDS  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE THE UNKOWN WORDS [1 point]\n",
    "HERE COMES YOUR ANALYSIS OF THE UNKNOWN WORDS AND YOUR EXPECTATION ON THE PERFORMANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Representing the tweet test data through embeddings [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REPRESENT THE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO ANAYSE THE UNKNOWN WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE THE UNKNOWN WORDS [1 point]\n",
    "HERE COMES YOUR ANALYSIS OF THE UNKNOWN WORDS AND YOUR EXPECTATION ON THE PERFORMANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Training and testing the classifier [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO TRAIN AND TEST AN SVM WITH THE EMBEDDING REPRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS OF THE TEST RESULT [2 points]\n",
    "\n",
    "HERE COMES YOUR ANALYSIS OF THE RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Testing the MELD classifiers on the tweet test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now trained and tested an emotion classifier on tweet data. What about the MELD classifiers that we built before and saved to disk? Can we load these and test them on the same test tweet data set?\n",
    "\n",
    "With embeddings this is easy because the representations are independent of the words but we need to use the same embedding model for both the training and testing. So if we used the *glove_twitter* embeddings for MELD with 25 dimensions, we have to do the same for the tweet test data.\n",
    "\n",
    "For the BoW classifiers, we need to use CountVectorizer and the *transform_fit* function to model the test data accordingly.\n",
    "\n",
    "If you saved the MELD models using the previous notebook, you can load the models now again. Otherwise, you need to rebuilt them, save them and next load them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Loading the MELD classifier for embedding representations [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE MELD EMBEDDING CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the vector representations for MELD and the test tweets were created using the same function and through the same embedding model we can now use it directly to classify the tweet test data we just created in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Testing the MELD Embedding classifier on the tweet test set [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO CLASSIFY THE TEST DATA WITH THE MELD EMBEDDING REPRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS OF THE TEST RESULT [2 points]\n",
    "\n",
    "HERE COMES YOUR ANALYSIS OF THE RESULT. COMPARE THESE WITH THE ABOVE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Representing and classifying the tweets as a bag-of-words vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Representing the tweets as BoW vectors [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to represent the test tweets according to our BoW vector representation derived from the MELD data, we need to load the *utterance_vec* file that we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE MELD BOW VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the transform function to the tokenized tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO REPRESENT THE TEST DATA ACCORDING TO MELD BOW VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the classifier and make the predictions on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Loading and testing the MELD BOW Classifier [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE MELD BOW CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO APPLY THE CLASSIFIER TO THE TWEET TEST SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS OF THE TEST RESULT [2 points]\n",
    "\n",
    "HERE COMES YOUR ANALYSIS OF THE RESULT. COMPARE THESE WITH THE ABOVE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of The assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
