{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2.1: Words, concepts, semantic relations in Wordnet-NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you are going to work with wordnet databases that have been incorporated in the NLTK package.\n",
    "Detailed information how to access and use wordnet can be found here: http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "Study the documentation and make yourself familiar with the different commands. Some of documentation is also explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up a word using the \"wn.synsets()\" function. This will give you a list of synsets in which the lookup string is matched with a lemma (synonym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synsets with \"dog\" as a synonym: 8\n",
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "all_dog_synsets = wn.synsets('dog')\n",
    "print('Number of synsets with \"dog\" as a synonym:', len(all_dog_synsets))\n",
    "print(all_dog_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the synsets in this list are printed by listing the first synonym only. Also note that we got nouns and verbs. We can iterate over the list to get each synset as an 'object' and next call specific functions for each synset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The synset = Synset('cat.n.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('cat.n.01.cat'), Lemma('cat.n.01.true_cat')]\n",
      "The definition = feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('feline.n.01'), Synset('cat.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  13\n",
      "\n",
      "The synset = Synset('guy.n.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('guy.n.01.guy'), Lemma('guy.n.01.cat'), Lemma('guy.n.01.hombre'), Lemma('guy.n.01.bozo')]\n",
      "The definition = an informal term for a youth or man\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('adult.n.01'), Synset('man.n.01'), Synset('guy.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('adult.n.01'), Synset('man.n.01'), Synset('guy.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('male.n.02'), Synset('man.n.01'), Synset('guy.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('male.n.02'), Synset('man.n.01'), Synset('guy.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  9\n",
      "\n",
      "The synset = Synset('cat.n.03')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('cat.n.03.cat')]\n",
      "The definition = a spiteful woman gossip\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('communicator.n.01'), Synset('gossip.n.03'), Synset('cat.n.03')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('communicator.n.01'), Synset('gossip.n.03'), Synset('cat.n.03')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('adult.n.01'), Synset('woman.n.01'), Synset('cat.n.03')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('adult.n.01'), Synset('woman.n.01'), Synset('cat.n.03')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('female.n.02'), Synset('woman.n.01'), Synset('cat.n.03')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('female.n.02'), Synset('woman.n.01'), Synset('cat.n.03')]]\n",
      "The maximum depth of its hyponymy chain is =  9\n",
      "\n",
      "The synset = Synset('kat.n.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('kat.n.01.kat'), Lemma('kat.n.01.khat'), Lemma('kat.n.01.qat'), Lemma('kat.n.01.quat'), Lemma('kat.n.01.cat'), Lemma('kat.n.01.Arabian_tea'), Lemma('kat.n.01.African_tea')]\n",
      "The definition = the leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('agent.n.03'), Synset('drug.n.01'), Synset('stimulant.n.02'), Synset('kat.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('matter.n.03'), Synset('substance.n.07'), Synset('agent.n.03'), Synset('drug.n.01'), Synset('stimulant.n.02'), Synset('kat.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  7\n",
      "\n",
      "The synset = Synset('cat-o'-nine-tails.n.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('cat-o'-nine-tails.n.01.cat-o'-nine-tails'), Lemma('cat-o'-nine-tails.n.01.cat')]\n",
      "The definition = a whip with nine knotted cords\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('device.n.01'), Synset('instrument.n.01'), Synset('whip.n.01'), Synset('cat-o'-nine-tails.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  9\n",
      "\n",
      "The synset = Synset('caterpillar.n.02')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('caterpillar.n.02.Caterpillar'), Lemma('caterpillar.n.02.cat')]\n",
      "The definition = a large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('container.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('tracked_vehicle.n.01'), Synset('caterpillar.n.02')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('conveyance.n.03'), Synset('vehicle.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('tracked_vehicle.n.01'), Synset('caterpillar.n.02')]]\n",
      "The maximum depth of its hyponymy chain is =  11\n",
      "\n",
      "The synset = Synset('big_cat.n.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('big_cat.n.01.big_cat'), Lemma('big_cat.n.01.cat')]\n",
      "The definition = any of several large cats typically able to roar and living in the wild\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('feline.n.01'), Synset('big_cat.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  13\n",
      "\n",
      "The synset = Synset('computerized_tomography.n.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('computerized_tomography.n.01.computerized_tomography'), Lemma('computerized_tomography.n.01.computed_tomography'), Lemma('computerized_tomography.n.01.CT'), Lemma('computerized_tomography.n.01.computerized_axial_tomography'), Lemma('computerized_tomography.n.01.computed_axial_tomography'), Lemma('computerized_tomography.n.01.CAT')]\n",
      "The definition = a method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis\n",
      "The full path of hypernyms = [[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('psychological_feature.n.01'), Synset('event.n.01'), Synset('act.n.02'), Synset('activity.n.01'), Synset('representation.n.10'), Synset('pictorial_representation.n.01'), Synset('imaging.n.02'), Synset('x-raying.n.01'), Synset('computerized_tomography.n.01')]]\n",
      "The maximum depth of its hyponymy chain is =  10\n",
      "\n",
      "The synset = Synset('cat.v.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('cat.v.01.cat')]\n",
      "The definition = beat with a cat-o'-nine-tails\n",
      "The full path of hypernyms = [[Synset('beat.v.02'), Synset('flog.v.01'), Synset('cat.v.01')]]\n",
      "The maximum depth of its hyponymy chain is =  2\n",
      "\n",
      "The synset = Synset('vomit.v.01')\n",
      "Type <class 'nltk.corpus.reader.wordnet.Synset'>\n",
      "The synonyms =  [Lemma('vomit.v.01.vomit'), Lemma('vomit.v.01.vomit_up'), Lemma('vomit.v.01.purge'), Lemma('vomit.v.01.cast'), Lemma('vomit.v.01.sick'), Lemma('vomit.v.01.cat'), Lemma('vomit.v.01.be_sick'), Lemma('vomit.v.01.disgorge'), Lemma('vomit.v.01.regorge'), Lemma('vomit.v.01.retch'), Lemma('vomit.v.01.puke'), Lemma('vomit.v.01.barf'), Lemma('vomit.v.01.spew'), Lemma('vomit.v.01.spue'), Lemma('vomit.v.01.chuck'), Lemma('vomit.v.01.upchuck'), Lemma('vomit.v.01.honk'), Lemma('vomit.v.01.regurgitate'), Lemma('vomit.v.01.throw_up')]\n",
      "The definition = eject the contents of the stomach through the mouth\n",
      "The full path of hypernyms = [[Synset('exhaust.v.05'), Synset('excrete.v.01'), Synset('vomit.v.01')]]\n",
      "The maximum depth of its hyponymy chain is =  2\n"
     ]
    }
   ],
   "source": [
    "for synset in all_dog_synsets:\n",
    "    print()\n",
    "    print('The synset =', synset)\n",
    "    print('Type', type(synset))\n",
    "    print('The synonyms = ', synset.lemmas())\n",
    "    print('The definition =', synset.definition())\n",
    "    print('The full path of hypernyms =', synset.hypernym_paths())\n",
    "    print('The maximum depth of its hyponymy chain is = ', synset.max_depth())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also obtain synsets with a certain part-of-speech only by passing a part-of-speech value as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "all_dog_verb_synsets = wn.synsets('dog', 'v')\n",
    "print(all_dog_verb_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various functions can be called on the synset object yielding different data structures. Try some to get a feeling for it. Below we show the specific relations that synsets can have besides hyponymy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part holonyms: []\n",
      "Member holonyms: [Synset('canis.n.01'), Synset('pack.n.06')]\n",
      "Substance holonyms: []\n",
      "Part meronyms: [Synset('flag.n.07')]\n",
      "Member meronyms: []\n",
      "Substance meronyms: []\n"
     ]
    }
   ],
   "source": [
    "doggy_synset = all_dog_synsets[0]\n",
    "#### Part - to -  whole relations:\n",
    "print('Part holonyms:',doggy_synset.part_holonyms())\n",
    "print('Member holonyms:',doggy_synset.member_holonyms())\n",
    "print('Substance holonyms:',doggy_synset.substance_holonyms())\n",
    "\n",
    "### Whole - to - part relations\n",
    "print('Part meronyms:',doggy_synset.part_meronyms())\n",
    "print('Member meronyms:',doggy_synset.member_meronyms())\n",
    "print('Substance meronyms:',doggy_synset.substance_meronyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caused: []\n",
      "Entailments: []\n",
      "Hyponyms: [Synset('hound.v.01'), Synset('quest.v.02'), Synset('run_down.v.07'), Synset('tree.v.03')]\n",
      "Examples: ['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n"
     ]
    }
   ],
   "source": [
    "chase_synset = all_dog_verb_synsets[0]\n",
    "#### Relations for verbal synsets\n",
    "print('Caused:', chase_synset.causes())\n",
    "print('Entailments:',chase_synset.entailments())\n",
    "print('Hyponyms:', chase_synset.hyponyms())\n",
    "print('Examples:', chase_synset.examples())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the full Python object definition of a synset to show all options, you can use the 'dir' command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'unicode_repr',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chase_synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these options may be familair to you if you have read the literature. We will look into the similarity functions more closely later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnets in other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are wordnets in many different languages and many are linked to English. The ones that are freely available in the Open Multilingual Wordnet platform: http://compling.hss.ntu.edu.sg/omw/ are also available in NLTK. You can use \"wn.langs\" to get the full list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might get an error regarding NLTK not finding a 'omw' dataset. You can download it just like you did in lab1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to /Users/piek/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out which languages have wordnets in the OMW package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['als',\n",
       " 'arb',\n",
       " 'bul',\n",
       " 'cat',\n",
       " 'cmn',\n",
       " 'dan',\n",
       " 'ell',\n",
       " 'eng',\n",
       " 'eus',\n",
       " 'fas',\n",
       " 'fin',\n",
       " 'fra',\n",
       " 'glg',\n",
       " 'heb',\n",
       " 'hrv',\n",
       " 'ind',\n",
       " 'ita',\n",
       " 'jpn',\n",
       " 'nld',\n",
       " 'nno',\n",
       " 'nob',\n",
       " 'pol',\n",
       " 'por',\n",
       " 'qcn',\n",
       " 'slv',\n",
       " 'spa',\n",
       " 'swe',\n",
       " 'tha',\n",
       " 'zsm']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wn.langs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listed language wordnets are created by translating the English synsets (the so-called Expand Method (Vossen (ed.) 1998). This means that the concepts of the English wordnet are re-used and the synonyms in the synsets are translated.\n",
    "\n",
    "Since the concept structure is the same for all these wordnets (they share the English concepts), you can  ask for the language lemmas linked to any synset in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any Japanese lemmas linked to English dog sense 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['イヌ', 'ドッグ', '洋犬', '犬', '飼犬', '飼い犬']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any Japanese lemmas linked to English dog sense 1\n",
    "wn.synset('dog.n.01').lemma_names('jpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cane', 'Canis_familiaris']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same for Dutch\n",
    "wn.synset('dog.n.01').lemma_names('ita')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is great but can we also get the synset directly through a Dutch or Japanese synonym?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog.n.01.hond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately not. You cannot directly get the synsets in Wordnet through the same interface we have used before for 'dog'. The next call therefore also does not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synsets with \"hond\" as a synonym: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_dog_synsets = wn.synsets('hond')\n",
    "print('Number of synsets with \"hond\" as a synonym:', len(all_dog_synsets))\n",
    "print(all_dog_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the synsets for a non-English word, we first have to use the wn.lemmas() function to get the list of lemma objects for a specific language. The next cell shows this for the Dutch lemma *hond*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.hond'), Lemma('asshole.n.01.hond')]\n"
     ]
    }
   ],
   "source": [
    "dutch_dog_lemmas = wn.lemmas('hond', lang='nld')\n",
    "print(dutch_dog_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.wordnet.Lemma"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dutch_dog_lemmas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemma is yet another object with attributes and functions, some of which overlap with those of a synset. Let's check them out through 'dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_frame_ids',\n",
       " '_frame_strings',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_key',\n",
       " '_lang',\n",
       " '_lex_id',\n",
       " '_lexname_index',\n",
       " '_name',\n",
       " '_related',\n",
       " '_synset',\n",
       " '_syntactic_marker',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'antonyms',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'count',\n",
       " 'derivationally_related_forms',\n",
       " 'entailments',\n",
       " 'frame_ids',\n",
       " 'frame_strings',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'key',\n",
       " 'lang',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'name',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'pertainyms',\n",
       " 'region_domains',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'synset',\n",
       " 'syntactic_marker',\n",
       " 'topic_domains',\n",
       " 'unicode_repr',\n",
       " 'usage_domains',\n",
       " 'verb_groups']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_lemma = dutch_dog_lemmas[0]\n",
    "dir(dutch_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some are different from synset such as lang(). The function *.synset()* can be used to get the synsets associated with a lemma. Obviously, the synset information is the same as for the English wordnet because the Open Dutch Wordnet: http://wordpress.let.vupr.nl/odwn/ was created by expanding the English wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('dog.n.01.hond') nld\n",
      "Synsets: Synset('dog.n.01')\n",
      "Hypernyms: [Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "Definition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "Hyponymy paths: [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('canine.n.02'), Synset('dog.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('domestic_animal.n.01'), Synset('dog.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "print(dutch_lemma, dutch_lemma.lang())\n",
    "\n",
    "dutch_dog_synset = dutch_lemma.synset()\n",
    "print('Synsets:', dutch_dog_synset)\n",
    "print('Hypernyms:', dutch_dog_synset.hypernyms())\n",
    "print('Definition:', dutch_dog_synset.definition())\n",
    "print('Hyponymy paths:', dutch_dog_synset.hypernym_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have many wordnets in different languages. Can we get statistics on their coverage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch: 36896\n",
      "Italian: 31477\n",
      "Japanese: 64797\n",
      "Slovene: 31631\n",
      "Spanish: 28647\n"
     ]
    }
   ],
   "source": [
    "print('Dutch:', len(list(wn.all_lemma_names(pos='n', lang='nld'))))\n",
    "print('Italian:', len(list(wn.all_lemma_names(pos='n', lang='ita'))))\n",
    "print('Japanese:', len(list(wn.all_lemma_names(pos='n', lang='jpn'))))\n",
    "print('Slovene:', len(list(wn.all_lemma_names(pos='n', lang='slv'))))\n",
    "\n",
    "print('Spanish:', len(list(wn.all_lemma_names(pos='n', lang='spa'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Dutch and Japanese dogs\n",
    "\n",
    "The next simple \"for\" loop iterates over all dog-hyponyms in the English wordnet and prints the synset and any Dutch and Japanese labels. We can easily see, which dogs are included in each language and which are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs: 18\n",
      "Synset('basenji.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['basenji', 'cane_del_Congo']\n",
      "Spanish: ['basenji']\n",
      "\n",
      "Synset('corgi.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウェルシュ・コーギー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('cur.n.01')\n",
      "Dutch: ['mormel', 'idioot', 'halve_gare', 'bastaard', 'bastaardhond', 'straathond']\n",
      "Japanese: ['雑犬', '雑種犬', '駄犬']\n",
      "Italian: ['bastardo']\n",
      "Spanish: ['chucho', 'gozque', 'mestizo']\n",
      "\n",
      "Synset('dalmatian.n.02')\n",
      "Dutch: ['dalmatiër', 'Dalmatische']\n",
      "Japanese: []\n",
      "Italian: ['dalmata']\n",
      "Spanish: []\n",
      "\n",
      "Synset('great_pyrenees.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['mastino_dei_Pirenei']\n",
      "Spanish: []\n",
      "\n",
      "Synset('griffon.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['グリフォン', 'ブリュッセルグリフォン', 'グリフォンブリュッセロワ']\n",
      "Italian: []\n",
      "Spanish: ['grifón']\n",
      "\n",
      "Synset('hunting_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['猟犬']\n",
      "Italian: ['cane_da_caccia']\n",
      "Spanish: []\n",
      "\n",
      "Synset('lapdog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['cagnolino', 'cagnolino_da_salotto']\n",
      "Spanish: []\n",
      "\n",
      "Synset('leonberg.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('mexican_hairless.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('newfoundland.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['terranova', 'Terranova']\n",
      "Spanish: []\n",
      "\n",
      "Synset('pooch.n.01')\n",
      "Dutch: ['bastaard', 'vuilnisbakkie']\n",
      "Japanese: ['わんこ', 'わんわん', 'わんちゃん']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('poodle.n.01')\n",
      "Dutch: ['poedel']\n",
      "Japanese: ['プードル']\n",
      "Italian: ['barbone']\n",
      "Spanish: []\n",
      "\n",
      "Synset('pug.n.01')\n",
      "Dutch: ['mops', 'mopshond']\n",
      "Japanese: ['パグ']\n",
      "Italian: []\n",
      "Spanish: ['pug']\n",
      "\n",
      "Synset('puppy.n.01')\n",
      "Dutch: ['hondejong', 'hondenjong', 'pup', 'puppy']\n",
      "Japanese: ['仔犬', '子犬', '小犬', '犬ころ', '犬児', '犬子', '狆ころ']\n",
      "Italian: ['cucciolo']\n",
      "Spanish: []\n",
      "\n",
      "Synset('spitz.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['spitz']\n",
      "\n",
      "Synset('toy_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['愛玩犬']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('working_dog.n.01')\n",
      "Dutch: ['werkhond']\n",
      "Japanese: ['ワーキングドッグ']\n",
      "Italian: ['cane_da_lavoro']\n",
      "Spanish: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synset ('dog.n.01')\n",
    "dogs = dog.hyponyms()\n",
    "print('Number of dogs:', len(dogs))\n",
    "\n",
    "for s in dogs:\n",
    "    print(s)\n",
    "    print('Dutch:', s.lemma_names('nld'))\n",
    "    print('Japanese:', s.lemma_names('jpn'))\n",
    "    print('Italian:', s.lemma_names('ita'))\n",
    "    print('Spanish:', s.lemma_names('spa'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives dogs as direct hyponyms but maybe there are more dogs as hyponyms of hyponyms of hyponyms, etc.  The WordNet interface documentation uses a so-called anonymous function (lambda) which is applied recursively to synsets that are the hyponyms of synsets. This is higher Python magic. For now accept that it traverses the hyponym tree from a starting synset and puts all results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo = lambda s: s.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs: 189\n"
     ]
    }
   ],
   "source": [
    "dogs_at_all_levels = list(dog.closure(hypo))\n",
    "print('Number of dogs:', len(dogs_at_all_levels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh, we now have 189 dogs instead of 18 if we go deeper! Let's check their coverage in Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('basenji.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['basenji', 'cane_del_Congo']\n",
      "Spanish: ['basenji']\n",
      "\n",
      "Synset('corgi.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウェルシュ・コーギー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('cur.n.01')\n",
      "Dutch: ['mormel', 'idioot', 'halve_gare', 'bastaard', 'bastaardhond', 'straathond']\n",
      "Japanese: ['雑犬', '雑種犬', '駄犬']\n",
      "Italian: ['bastardo']\n",
      "Spanish: ['chucho', 'gozque', 'mestizo']\n",
      "\n",
      "Synset('dalmatian.n.02')\n",
      "Dutch: ['dalmatiër', 'Dalmatische']\n",
      "Japanese: []\n",
      "Italian: ['dalmata']\n",
      "Spanish: []\n",
      "\n",
      "Synset('great_pyrenees.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['mastino_dei_Pirenei']\n",
      "Spanish: []\n",
      "\n",
      "Synset('griffon.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['グリフォン', 'ブリュッセルグリフォン', 'グリフォンブリュッセロワ']\n",
      "Italian: []\n",
      "Spanish: ['grifón']\n",
      "\n",
      "Synset('hunting_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['猟犬']\n",
      "Italian: ['cane_da_caccia']\n",
      "Spanish: []\n",
      "\n",
      "Synset('lapdog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['cagnolino', 'cagnolino_da_salotto']\n",
      "Spanish: []\n",
      "\n",
      "Synset('leonberg.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('mexican_hairless.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('newfoundland.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['terranova', 'Terranova']\n",
      "Spanish: []\n",
      "\n",
      "Synset('pooch.n.01')\n",
      "Dutch: ['bastaard', 'vuilnisbakkie']\n",
      "Japanese: ['わんこ', 'わんわん', 'わんちゃん']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('poodle.n.01')\n",
      "Dutch: ['poedel']\n",
      "Japanese: ['プードル']\n",
      "Italian: ['barbone']\n",
      "Spanish: []\n",
      "\n",
      "Synset('pug.n.01')\n",
      "Dutch: ['mops', 'mopshond']\n",
      "Japanese: ['パグ']\n",
      "Italian: []\n",
      "Spanish: ['pug']\n",
      "\n",
      "Synset('puppy.n.01')\n",
      "Dutch: ['hondejong', 'hondenjong', 'pup', 'puppy']\n",
      "Japanese: ['仔犬', '子犬', '小犬', '犬ころ', '犬児', '犬子', '狆ころ']\n",
      "Italian: ['cucciolo']\n",
      "Spanish: []\n",
      "\n",
      "Synset('spitz.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['spitz']\n",
      "\n",
      "Synset('toy_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['愛玩犬']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('working_dog.n.01')\n",
      "Dutch: ['werkhond']\n",
      "Japanese: ['ワーキングドッグ']\n",
      "Italian: ['cane_da_lavoro']\n",
      "Spanish: []\n",
      "\n",
      "Synset('cardigan.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['カーディガン']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('pembroke.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ペンブローク']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('feist.n.01')\n",
      "Dutch: ['Feist']\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('pariah_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['パイ', 'パリア', 'パリア犬']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('liver-spotted_dalmatian.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('brabancon_griffon.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ブラバンソングリフォン']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('courser.n.03')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('dachshund.n.01')\n",
      "Dutch: ['dashond', 'taks', 'teckel']\n",
      "Japanese: ['ダックスフント']\n",
      "Italian: ['bassotto']\n",
      "Spanish: ['dachshund']\n",
      "\n",
      "Synset('hound.n.01')\n",
      "Dutch: ['jachthond']\n",
      "Japanese: ['狩犬', '狩り犬', '猟犬', '猟り犬', '走狗']\n",
      "Italian: ['bracco', 'segugio']\n",
      "Spanish: []\n",
      "\n",
      "Synset('rhodesian_ridgeback.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('sporting_dog.n.01')\n",
      "Dutch: ['vogelhond']\n",
      "Japanese: ['猟犬']\n",
      "Italian: ['bracco', 'cane_da_caccia']\n",
      "Spanish: ['perro_cazador', 'perro_de_caza']\n",
      "\n",
      "Synset('terrier.n.01')\n",
      "Dutch: ['terriër']\n",
      "Japanese: ['テリア']\n",
      "Italian: ['terrier']\n",
      "Spanish: ['terrier']\n",
      "\n",
      "Synset('large_poodle.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('miniature_poodle.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('standard_poodle.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['Poodle_de_estándar', 'Poodle_estándar']\n",
      "\n",
      "Synset('toy_poodle.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['barboncino_nano']\n",
      "Spanish: []\n",
      "\n",
      "Synset('chow.n.03')\n",
      "Dutch: ['eten']\n",
      "Japanese: ['チャウチャウ']\n",
      "Italian: []\n",
      "Spanish: ['chow_chow']\n",
      "\n",
      "Synset('keeshond.n.01')\n",
      "Dutch: ['keeshond']\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('pomeranian.n.01')\n",
      "Dutch: ['Pommers']\n",
      "Japanese: ['スピッツ']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('samoyed.n.03')\n",
      "Dutch: ['Samojeed']\n",
      "Japanese: []\n",
      "Italian: ['samoiedo']\n",
      "Spanish: []\n",
      "\n",
      "Synset('chihuahua.n.03')\n",
      "Dutch: ['chihuahua']\n",
      "Japanese: ['チワワ']\n",
      "Italian: ['chihuahua']\n",
      "Spanish: []\n",
      "\n",
      "Synset('japanese_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['狆']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('maltese_dog.n.01')\n",
      "Dutch: ['Maltese']\n",
      "Japanese: ['マルチーズ']\n",
      "Italian: ['maltese']\n",
      "Spanish: []\n",
      "\n",
      "Synset('pekinese.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ペキニーズ']\n",
      "Italian: ['pechinese']\n",
      "Spanish: []\n",
      "\n",
      "Synset('shih-tzu.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['シーズー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('toy_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['トイスパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('toy_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['トイテリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('boxer.n.04')\n",
      "Dutch: ['boxer', 'pugilist', 'vuistvechter', 'bokser']\n",
      "Japanese: ['ボクサー']\n",
      "Italian: ['boxer']\n",
      "Spanish: []\n",
      "\n",
      "Synset('bull_mastiff.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('bulldog.n.01')\n",
      "Dutch: ['buldog']\n",
      "Japanese: ['ブルドッグ']\n",
      "Italian: ['bulldog']\n",
      "Spanish: ['bulldog']\n",
      "\n",
      "Synset('eskimo_dog.n.01')\n",
      "Dutch: ['sledehond']\n",
      "Japanese: ['エスキモー犬']\n",
      "Italian: ['husky']\n",
      "Spanish: ['husky', 'perro_esquimal', 'perro_siberiano']\n",
      "\n",
      "Synset('great_dane.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['グレートデン']\n",
      "Italian: ['alano', 'danese']\n",
      "Spanish: ['Gran_Danés']\n",
      "\n",
      "Synset('guide_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['盲導犬']\n",
      "Italian: ['cane_per_ciechi']\n",
      "Spanish: ['perro_guía']\n",
      "\n",
      "Synset('hearing_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('mastiff.n.01')\n",
      "Dutch: ['bulhond', 'mastiff']\n",
      "Japanese: ['マスチフ', 'マスティフ']\n",
      "Italian: ['mastino']\n",
      "Spanish: []\n",
      "\n",
      "Synset('police_dog.n.01')\n",
      "Dutch: ['politiehond']\n",
      "Japanese: ['警察犬']\n",
      "Italian: ['cane_poliziotto']\n",
      "Spanish: ['perro_policía']\n",
      "\n",
      "Synset('saint_bernard.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['サンベルナール峠']\n",
      "Italian: ['San_Bernardo']\n",
      "Spanish: ['San_Bernardo']\n",
      "\n",
      "Synset('seizure-alert_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('sennenhunde.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('shepherd_dog.n.01')\n",
      "Dutch: ['herdershond']\n",
      "Japanese: ['シェパード', '牧羊犬']\n",
      "Italian: ['cane_da_pastore', 'cane_pastore']\n",
      "Spanish: ['perro_pastor']\n",
      "\n",
      "Synset('sled_dog.n.01')\n",
      "Dutch: ['sledehond']\n",
      "Japanese: []\n",
      "Italian: ['cane_da_slitta']\n",
      "Spanish: ['perro_de_trineo']\n",
      "\n",
      "Synset('watchdog.n.02')\n",
      "Dutch: ['waakhond']\n",
      "Japanese: ['ウォッチドッグ', '番犬']\n",
      "Italian: ['cane_da_guardia']\n",
      "Spanish: []\n",
      "\n",
      "Synset('sausage_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('afghan_hound.n.01')\n",
      "Dutch: ['Afghaanse_windhond']\n",
      "Japanese: ['アフガン', 'アフガンハウンド']\n",
      "Italian: ['levriero_afgano']\n",
      "Spanish: []\n",
      "\n",
      "Synset('basset.n.01')\n",
      "Dutch: ['brak']\n",
      "Japanese: ['バセットハウンド']\n",
      "Italian: ['bassethound', 'basset_hound']\n",
      "Spanish: []\n",
      "\n",
      "Synset('beagle.n.01')\n",
      "Dutch: ['snuffelaar', 'beagle', 'brak']\n",
      "Japanese: ['ビーグル']\n",
      "Italian: ['beagle']\n",
      "Spanish: []\n",
      "\n",
      "Synset('bloodhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ブラッドハウンド', 'ブラッドハウンド犬', '警察犬']\n",
      "Italian: ['bracco', 'limiere', 'segugio']\n",
      "Spanish: []\n",
      "\n",
      "Synset('bluetick.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('boarhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('coonhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('foxhound.n.01')\n",
      "Dutch: ['vossenjacht']\n",
      "Japanese: ['フォックスハウンド']\n",
      "Italian: []\n",
      "Spanish: ['foxhound']\n",
      "\n",
      "Synset('greyhound.n.01')\n",
      "Dutch: ['hazewind', 'hazewindhond', 'windhond']\n",
      "Japanese: []\n",
      "Italian: ['levriere', 'levriero', 'veltro']\n",
      "Spanish: ['galgo_inglés']\n",
      "\n",
      "Synset('harrier.n.02')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('ibizan_hound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('norwegian_elkhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('otterhound.n.01')\n",
      "Dutch: ['hond_voor_jacht_op_otters']\n",
      "Japanese: ['オッターハウンド']\n",
      "Italian: []\n",
      "Spanish: ['otterhound']\n",
      "\n",
      "Synset('plott_hound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('redbone.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('saluki.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['levriero_persiano', 'saluki']\n",
      "Spanish: []\n",
      "\n",
      "Synset('scottish_deerhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['levriero_inglese_a_pelo_ruvido']\n",
      "Spanish: []\n",
      "\n",
      "Synset('staghound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('weimaraner.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('wolfhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウルフハウンド']\n",
      "Italian: ['cane_lupo']\n",
      "Spanish: []\n",
      "\n",
      "Synset('bird_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('griffon.n.03')\n",
      "Dutch: []\n",
      "Japanese: ['グリフォン']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('pointer.n.04')\n",
      "Dutch: []\n",
      "Japanese: ['ポインター']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('retriever.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['自動引下器']\n",
      "Italian: ['cane_da_riporto']\n",
      "Spanish: []\n",
      "\n",
      "Synset('setter.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['セッター']\n",
      "Italian: ['setter']\n",
      "Spanish: []\n",
      "\n",
      "Synset('spaniel.n.01')\n",
      "Dutch: ['spaniël']\n",
      "Japanese: ['スパニエル']\n",
      "Italian: ['epagneul']\n",
      "Spanish: []\n",
      "\n",
      "Synset('water_dog.n.02')\n",
      "Dutch: ['waterhond']\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('airedale.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('australian_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('bedlington_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ベドリントン・テリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('border_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('boston_bull.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('bullterrier.n.01')\n",
      "Dutch: ['bulterriër']\n",
      "Japanese: []\n",
      "Italian: ['bull_terrier']\n",
      "Spanish: []\n",
      "\n",
      "Synset('cairn.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['ケアーン・テリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('dandie_dinmont.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('fox_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['フォックステリア']\n",
      "Italian: ['fox_terrier', 'fox-terrier']\n",
      "Spanish: []\n",
      "\n",
      "Synset('irish_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('kerry_blue_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('lhasa.n.02')\n",
      "Dutch: []\n",
      "Japanese: ['ラサ']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('norfolk_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('norwich_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('rat_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('schnauzer.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['シュナウザー', 'シュナウツァー']\n",
      "Italian: ['schnauzer']\n",
      "Spanish: []\n",
      "\n",
      "Synset('scotch_terrier.n.01')\n",
      "Dutch: ['Schotse_terriër']\n",
      "Japanese: ['スコッチテリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('silky_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('skye_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('soft-coated_wheaten_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('tibetan_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('west_highland_white_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウエスト・ハイランド・ホワイト・テリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('wirehair.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('yorkshire_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ヨークシャーテリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('english_toy_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('king_charles_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['キングチャールズスパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('papillon.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['パピヨン']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('french_bulldog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['フレンチ・ブルドッグ']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('seeing_eye_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['盲導犬']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('tibetan_mastiff.n.01')\n",
      "Dutch: ['Tibetaanse_mastiff']\n",
      "Japanese: ['チベタンマスチフ']\n",
      "Italian: ['mastino_del_Tibet']\n",
      "Spanish: []\n",
      "\n",
      "Synset('appenzeller.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('bernese_mountain_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['バーニーズ・マウンテン・ドッグ']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('entlebucher.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('greater_swiss_mountain_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('belgian_sheepdog.n.01')\n",
      "Dutch: ['belgische_herder']\n",
      "Japanese: []\n",
      "Italian: ['pastore_belga']\n",
      "Spanish: ['pastor_belga']\n",
      "\n",
      "Synset('border_collie.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ボーダー・コリー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('bouvier_des_flandres.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('briard.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['pastor_de_brie']\n",
      "\n",
      "Synset('collie.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['コリー']\n",
      "Italian: ['collie', 'pastore_scozzese']\n",
      "Spanish: []\n",
      "\n",
      "Synset('german_shepherd.n.01')\n",
      "Dutch: ['Duitse_herdershond']\n",
      "Japanese: ['シェパード']\n",
      "Italian: ['alsaziano', 'cane_lupo', 'pastore_tedesco']\n",
      "Spanish: []\n",
      "\n",
      "Synset('kelpie.n.02')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('komondor.n.01')\n",
      "Dutch: ['komondor']\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['komondor']\n",
      "\n",
      "Synset('old_english_sheepdog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ボブテール']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('rottweiler.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('shetland_sheepdog.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['シェットランド・シープドッグ']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('malamute.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['アラスカン・マラミュート']\n",
      "Italian: ['alaskan_malamut', 'malamut']\n",
      "Spanish: []\n",
      "\n",
      "Synset('siberian_husky.n.01')\n",
      "Dutch: ['Siberische_husky']\n",
      "Japanese: ['シベリアンハスキー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('attack_dog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('housedog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['perro_guardián']\n",
      "\n",
      "Synset('kuvasz.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('pinscher.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['pinscher']\n",
      "\n",
      "Synset('schipperke.n.01')\n",
      "Dutch: ['schippersklokje', 'schippertje']\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['schipperke']\n",
      "\n",
      "Synset('black-and-tan_coonhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('coondog.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['coondog']\n",
      "\n",
      "Synset('american_foxhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('english_foxhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('walker_hound.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['perro_raposero', 'perro_zorrero']\n",
      "\n",
      "Synset('italian_greyhound.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['イタリアン・グレーハウンド']\n",
      "Italian: ['levriero_italiano', 'piccolo_levriero_italiano']\n",
      "Spanish: []\n",
      "\n",
      "Synset('whippet.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['piccolo_levriero_inglese', 'whippet']\n",
      "Spanish: ['whippet']\n",
      "\n",
      "Synset('borzoi.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ボルゾイ']\n",
      "Italian: ['borzoi', 'levriero_russo']\n",
      "Spanish: ['borzoi']\n",
      "\n",
      "Synset('irish_wolfhound.n.01')\n",
      "Dutch: ['trillen_op_zijn_benen']\n",
      "Japanese: ['アイリッシュウルフハウンド']\n",
      "Italian: ['levriero_irlandese']\n",
      "Spanish: []\n",
      "\n",
      "Synset('german_short-haired_pointer.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('vizsla.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: ['vizsla']\n",
      "\n",
      "Synset('chesapeake_bay_retriever.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['チェサピーク・ベイ・レトリーバー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('curly-coated_retriever.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('flat-coated_retriever.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('golden_retriever.n.01')\n",
      "Dutch: ['golden_retriever']\n",
      "Japanese: ['ゴールデン・レトリバー']\n",
      "Italian: ['golden_retriever']\n",
      "Spanish: []\n",
      "\n",
      "Synset('labrador_retriever.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ラブラドール・レトリバー']\n",
      "Italian: ['labrador', 'labrador_retriever']\n",
      "Spanish: []\n",
      "\n",
      "Synset('english_setter.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('gordon_setter.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('irish_setter.n.01')\n",
      "Dutch: ['Ierse_setter']\n",
      "Japanese: ['アイリッシュ・セッター']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('brittany_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('clumber.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('cocker_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['コッカースパニエル']\n",
      "Italian: ['cocker']\n",
      "Spanish: []\n",
      "\n",
      "Synset('field_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('springer_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['スプリンガースパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('sussex_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('water_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウォータースパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('american_staffordshire_terrier.n.01')\n",
      "Dutch: ['pitbullterriër']\n",
      "Japanese: ['アメリカン・ピット・ブル・テリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('staffordshire_bullterrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('smooth-haired_fox_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('wire-haired_fox_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('manchester_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('giant_schnauzer.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ジャイアント・シュナウザー']\n",
      "Italian: ['schnauzer_gigante']\n",
      "Spanish: []\n",
      "\n",
      "Synset('miniature_schnauzer.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ミニチュア・シュナウザー']\n",
      "Italian: ['schnauzer_nano']\n",
      "Spanish: []\n",
      "\n",
      "Synset('standard_schnauzer.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['schnauzer_medio']\n",
      "Spanish: ['Schnauzer_estándar']\n",
      "\n",
      "Synset('clydesdale_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('lakeland_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('welsh_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウェルシュテリア']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('blenheim_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ブレナムスパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('groenendael.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['pastore_belga_Groenendael']\n",
      "Spanish: []\n",
      "\n",
      "Synset('malinois.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['pastore_belga_di_Malines']\n",
      "Spanish: ['Malinois']\n",
      "\n",
      "Synset('affenpinscher.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['アーフェンピンシャー']\n",
      "Italian: []\n",
      "Spanish: ['affenpinscher']\n",
      "\n",
      "Synset('doberman.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: ['doberman']\n",
      "Spanish: []\n",
      "\n",
      "Synset('miniature_pinscher.n.01')\n",
      "Dutch: ['dwergpinscher']\n",
      "Japanese: ['ミニチュア・ピンシャー']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('english_springer.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['イングリッシュ・スプリンガー・スパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('welsh_springer_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: ['ウェルシュスプリンガースパニエル']\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('american_water_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('irish_water_spaniel.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('toy_manchester.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n",
      "Synset('sealyham_terrier.n.01')\n",
      "Dutch: []\n",
      "Japanese: []\n",
      "Italian: []\n",
      "Spanish: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for s in dogs_at_all_levels: \n",
    "    print(s)\n",
    "    print('Dutch:', s.lemma_names('nld'))\n",
    "    print('Japanese:', s.lemma_names('jpn'))\n",
    "    print('Italian:', s.lemma_names('ita'))\n",
    "    print('Spanish:', s.lemma_names('spa'))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the non-English wordnets lack coverage compared to the English WordNet. There is work to do to complete it. Perhaps a nice project for you to work on to increase the coverage of our Dutch WordNet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next simple code counts the missing dogs per language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dogs in Dutch: 142\n",
      "Missing dogs in Japanse: 100\n",
      "Missing dogs in Italian: 127\n",
      "Missing dogs in Spanish: 154\n"
     ]
    }
   ],
   "source": [
    "dog_gaps_nl = 0\n",
    "dog_gaps_jp = 0\n",
    "dog_gaps_es = 0\n",
    "dog_gaps_it = 0\n",
    "\n",
    "\n",
    "for s in dogs_at_all_levels: \n",
    "    if not s.lemma_names('nld'):\n",
    "        dog_gaps_nl +=1\n",
    "    \n",
    "    if not s.lemma_names('jpn'):\n",
    "        dog_gaps_jp +=1\n",
    "    \n",
    "    if not s.lemma_names('ita'):\n",
    "        dog_gaps_it +=1\n",
    "    \n",
    "    if not s.lemma_names('spa'):\n",
    "        dog_gaps_es +=1\n",
    "        \n",
    "print('Missing dogs in Dutch:', dog_gaps_nl)\n",
    "print('Missing dogs in Japanse:', dog_gaps_jp)\n",
    "print('Missing dogs in Italian:', dog_gaps_it)\n",
    "print('Missing dogs in Spanish:', dog_gaps_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: are there any Dutch words for dogs that are not in the English WordNet? Where can you find the answer to such a question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet Similarity\n",
    "\n",
    "A whole series of similarity functions have been added to NLTK and can be used for scoring synset pairs. See the documentation for the other methods. We show here how it works for \"path\"\n",
    "\n",
    "We first obtain a few synsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "car = wn.synset('car.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the full hypernym path for these synsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs are a type of: [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('canine.n.02'), Synset('dog.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('domestic_animal.n.01'), Synset('dog.n.01')]]\n",
      "cats are a type of: [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('feline.n.01'), Synset('cat.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "print('dogs are a type of:', dog.hypernym_paths())\n",
    "print('cats are a type of:', cat.hypernym_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a large parts of the pathes are the same, starting from *carnivore*. Also note that *dog* has two branches one through *domestic_animal* and another one through *canine*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars are a type of: [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('container.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('motor_vehicle.n.01'), Synset('car.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('artifact.n.01'), Synset('instrumentality.n.03'), Synset('conveyance.n.03'), Synset('vehicle.n.01'), Synset('wheeled_vehicle.n.01'), Synset('self-propelled_vehicle.n.01'), Synset('motor_vehicle.n.01'), Synset('car.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "print('cars are a type of:', car.hypernym_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the path for *car* is very different but at some point meets the other pathes at *whole.n.02*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet similarity measures compare the distance from word meanings through the hypernym path and possibly other relations.\n",
    "\n",
    "Synsets have the similarity function built in. The function requires another synset as the input and gives back a score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(dog.path_similarity(cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this very similar? The only way to find out is to compare this with others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05555555555555555\n",
      "0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "print(car.path_similarity(cat))\n",
    "print(car.path_similarity(dog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, these score a lot lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see of this also works for verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14285714285714285\n",
      "0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "hit = wn.synset('hit.v.01')\n",
    "slap = wn.synset('slap.v.01')\n",
    "print(hit.path_similarity(slap))\n",
    "print(wn.path_similarity(hit, slap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to work as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did some readings on WordNet, you may know that the noun hierarchy has a single top-node synset 'entity-n-01'. All nominal synsets decent from this synset. This is not the case for verbs nor for adjectives. The verb part of WordNet therefore consists of '559' islands of disconnected synsets with 559 rootnodes. The English WordNet editors decided not to connect these islands in an artificial way as was done for nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit is a type of: [[Synset('move.v.02'), Synset('propel.v.01'), Synset('hit.v.01')]]\n",
      "slap is a type of: [[Synset('touch.v.01'), Synset('strike.v.01'), Synset('slap.v.01')]]\n"
     ]
    }
   ],
   "source": [
    "print('hit is a type of:', hit.hypernym_paths())\n",
    "print('slap is a type of:', slap.hypernym_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is no overlap between the pathes for the two verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see this using the NLTK root_hypernyms() function for the above noun and verb synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root for hit: [Synset('entity.n.01')]\n",
      "Root for hit: [Synset('entity.n.01')]\n",
      "Root for hit: [Synset('touch.v.01')]\n",
      "Root for hit: [Synset('move.v.02')]\n"
     ]
    }
   ],
   "source": [
    "print('Root for hit:', dog.root_hypernyms())\n",
    "print('Root for hit:', cat.root_hypernyms())\n",
    "print('Root for hit:', slap.root_hypernyms())\n",
    "print('Root for hit:', hit.root_hypernyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it still possible to get a value for similarity if the subgraphs are not connected? Well, the package imposes a simulated rootnode by grouping all the subgraph top-nodes under a single node. This is the default setting. If you do not want to use this, you can turn it off by setting the parameter *simulate_root* to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(hit.path_similarity(slap, simulate_root=False))\n",
    "print(wn.path_similarity(hit, slap, simulate_root=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(cat.path_similarity(cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the simulated root there is no path from 'hit' to 'slap'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using WordNet similarity for words instead of synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to use this for words, we first need to obtain all the synsets for a word and then compare each synset with the synsets of another word. We thus need a for-loop inside a for-loop. The first loop gets the synsets for the first word and the second loop for each synset the synsets for the second word to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') :\n",
      "\t Synset('cat.n.01') : 0.2\n",
      "\t Synset('guy.n.01') : 0.125\n",
      "\t Synset('cat.n.03') : 0.125\n",
      "\t Synset('kat.n.01') : 0.07692307692307693\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.08333333333333333\n",
      "\t Synset('caterpillar.n.02') : 0.07692307692307693\n",
      "\t Synset('big_cat.n.01') : 0.2\n",
      "\t Synset('computerized_tomography.n.01') : 0.05263157894736842\n",
      "Synset('frump.n.01') :\n",
      "\t Synset('cat.n.01') : 0.07142857142857142\n",
      "\t Synset('guy.n.01') : 0.125\n",
      "\t Synset('cat.n.03') : 0.125\n",
      "\t Synset('kat.n.01') : 0.1\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.07142857142857142\n",
      "\t Synset('caterpillar.n.02') : 0.06666666666666667\n",
      "\t Synset('big_cat.n.01') : 0.07142857142857142\n",
      "\t Synset('computerized_tomography.n.01') : 0.05555555555555555\n",
      "Synset('dog.n.03') :\n",
      "\t Synset('cat.n.01') : 0.07692307692307693\n",
      "\t Synset('guy.n.01') : 0.2\n",
      "\t Synset('cat.n.03') : 0.14285714285714285\n",
      "\t Synset('kat.n.01') : 0.1111111111111111\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.07692307692307693\n",
      "\t Synset('caterpillar.n.02') : 0.07142857142857142\n",
      "\t Synset('big_cat.n.01') : 0.07692307692307693\n",
      "\t Synset('computerized_tomography.n.01') : 0.058823529411764705\n",
      "Synset('cad.n.01') :\n",
      "\t Synset('cat.n.01') : 0.07692307692307693\n",
      "\t Synset('guy.n.01') : 0.14285714285714285\n",
      "\t Synset('cat.n.03') : 0.14285714285714285\n",
      "\t Synset('kat.n.01') : 0.1111111111111111\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.07692307692307693\n",
      "\t Synset('caterpillar.n.02') : 0.07142857142857142\n",
      "\t Synset('big_cat.n.01') : 0.07692307692307693\n",
      "\t Synset('computerized_tomography.n.01') : 0.058823529411764705\n",
      "Synset('frank.n.02') :\n",
      "\t Synset('cat.n.01') : 0.05263157894736842\n",
      "\t Synset('guy.n.01') : 0.08333333333333333\n",
      "\t Synset('cat.n.03') : 0.08333333333333333\n",
      "\t Synset('kat.n.01') : 0.09090909090909091\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.06666666666666667\n",
      "\t Synset('caterpillar.n.02') : 0.0625\n",
      "\t Synset('big_cat.n.01') : 0.05263157894736842\n",
      "\t Synset('computerized_tomography.n.01') : 0.05555555555555555\n",
      "Synset('pawl.n.01') :\n",
      "\t Synset('cat.n.01') : 0.058823529411764705\n",
      "\t Synset('guy.n.01') : 0.07692307692307693\n",
      "\t Synset('cat.n.03') : 0.07692307692307693\n",
      "\t Synset('kat.n.01') : 0.07142857142857142\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.14285714285714285\n",
      "\t Synset('caterpillar.n.02') : 0.1\n",
      "\t Synset('big_cat.n.01') : 0.058823529411764705\n",
      "\t Synset('computerized_tomography.n.01') : 0.05\n",
      "Synset('andiron.n.01') :\n",
      "\t Synset('cat.n.01') : 0.0625\n",
      "\t Synset('guy.n.01') : 0.08333333333333333\n",
      "\t Synset('cat.n.03') : 0.08333333333333333\n",
      "\t Synset('kat.n.01') : 0.07692307692307693\n",
      "\t Synset('cat-o'-nine-tails.n.01') : 0.16666666666666666\n",
      "\t Synset('caterpillar.n.02') : 0.1111111111111111\n",
      "\t Synset('big_cat.n.01') : 0.0625\n",
      "\t Synset('computerized_tomography.n.01') : 0.05263157894736842\n"
     ]
    }
   ],
   "source": [
    "w1='dog'\n",
    "w2='cat'\n",
    "for s1 in wn.synsets(w1, 'n'):\n",
    "    print(s1,':')\n",
    "    for s2 in wn.synsets(w2, 'n'):\n",
    "        print('\\t', s2,':', s1.path_similarity(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the highest similarity from all pairs to find the strongest association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar are Synset('dog.n.01') Synset('cat.n.01') : 0.2\n",
      "Most similar are Synset('frump.n.01') Synset('guy.n.01') : 0.125\n",
      "Most similar are Synset('dog.n.03') Synset('guy.n.01') : 0.2\n",
      "Most similar are Synset('cad.n.01') Synset('guy.n.01') : 0.14285714285714285\n",
      "Most similar are Synset('frank.n.02') Synset('kat.n.01') : 0.09090909090909091\n",
      "Most similar are Synset('pawl.n.01') Synset('cat-o'-nine-tails.n.01') : 0.14285714285714285\n",
      "Most similar are Synset('andiron.n.01') Synset('cat-o'-nine-tails.n.01') : 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "w1='dog'\n",
    "w2='cat'\n",
    "for s1 in wn.synsets(w1, 'n'):\n",
    "    top_sim_score = 0    \n",
    "    top_sim_synset_w1 = \"\"\n",
    "    top_sim_synset_w2 = \"\"\n",
    "    for s2 in wn.synsets(w2, 'n'):\n",
    "        sim = s1.path_similarity(s2)\n",
    "        if sim>top_sim_score:\n",
    "            top_sim_score = sim\n",
    "            top_sim_synset_w2 = s2\n",
    "    print('Most similar are', s1, top_sim_synset_w2,':', top_sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
