{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab5 Final assignment: putting things together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final assignment is an individual assignment in which you have to put things together:\n",
    "\n",
    "   1. **Create and annotate a conversation**\n",
    "       1. **BONUS POINT**: adapt the **eliza_language.py** to get better Eliza responses that trigger Ekman emotions \n",
    "       2. create an emotional conversation between a **fake** human and your version of Eliza consisting of 50 human input prompts (a total of 100 turn ids inclduing the prompts from Eliza): use **eliza-chat.ipynb**.\n",
    "       3. annotate the conversation with Ekman emotions with the gold emotion labels and save the result to disk: : use **eliza-chat.ipynb**.\n",
    "   2. **Automatically clasify the emotions using different classifiers**\n",
    "       1. load the annotated conversation from disk in this notebook as a Pandas dataframe and apply the following emotion classifiers to your conversation:\n",
    "       2. BoW SVM classifiers trained on 1) MELD, 2) Tweets and 3) MELD+Tweets data.\n",
    "       3. BERT finetuned with GO_emotions (as shown below)\n",
    "       4. **BONUS POINT**: Apply VADER to get sentiment scores for each utterance\n",
    "   3. **Evaluate the classifiers against you gold annotations**\n",
    "       1. Create a classification report and confusion matrix. Only evaluate the human input and ignore the ELiza prompts!\n",
    "       2. Discuss their performance and result: 1) report on similarities and differences, 2) formulate what you expected from each model in terms of recall and precision and whether this is confirmed or not by the results 3) try to explain what did NOT confirm your expectations \n",
    "       3. **BONUS POINT**: If you also applied VADER and mapped the Ekman labels to sentiment, you can get an evaluation of all the cassifiers are the sentiment level as well.\n",
    "   4. **Formulate what could be done to improve the automatic classification**\n",
    "       1. How can you improve the classifiers by 1) different training data, 2) processing the training data differently\n",
    "       2. Reflect on using different emotion labels: sentiment, ekman or go.\n",
    "\n",
    "To be able to run the experiment, you need to have an emotional conversation with Eliza using the notebook **eliza_chat.ipynb** with 50 human turns as input, annotate this conversation with the Ekman emotion labels and save it to disk. Try to make it a **fake** but emotional conversation, so basicaly an emotional roller coaster exhibiting many different emotions to properly test the classifiers. You can earn maximal **1 bonus point** by adapting Eliza's responses in an intelligent way to respond better to get Ekman emotions.\n",
    "\n",
    "For the automatoc classifications, you can use the BoW SVM classifiers that you created in Lab3. You should have saved these classifiers on disk and load these in this notebook. You should also build a 3rd BoW SVM classfier by combining the MELD and Tweet data into a single set of training data. Save the MELD-Tweet classifier to disk as well and load it in this notebook. You can look at **aggregating_results_across_systems.ipynb** to see how to load different classifiers from disk and to aggregate the results in a single pandas dataframe.\n",
    "\n",
    "Below, we already show how you can apply the finetuned BERT classifier to the loaded conversation and add the result to the pandas dataframe. You can simply apply this to your own conversation. If for some reason, you are not able to load the transformer model in your computer and run it do the following:\n",
    "\n",
    "   1. Send me your conversation with the annotation saved in CSV\n",
    "   2. I will apply the transformer model for you and send back the CSV with the GO annotations\n",
    "   3. Load the CSV with the GO anotations and proceed from there\n",
    "\n",
    "Once the pandasframe is complete with the annotations from all the classifiers, make sure you save it to disk first for future use.\n",
    "\n",
    "For the evaluation of the classifiers, you need to extract the gold labels and the classifier labels for each of them separately. Use the **sklearn** functions to generate a classification report and a confusion matrix (you can use **seaborn** to make the image nicer). You can earn **1 bonus point** max, if you also applied VADER to the conversation and evaluated the systems at the sentiment level. Note that you need to provide a mapping from Ekman to sentiment for your BoW classifiers. You can use the functions in **lab5_util.py** to apply such a mapping to your results.\n",
    "\n",
    "When you report the results, it makes sense to combine these in a single table. So instead of having 4 Ekman emotion classification tables you can give the recall, precision and f1 scores 4 times for each emotion and averaged in a multicolumn table. This makes it easier to observe differences and similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment should be submitted individually on CANVAS as a zipfile and include the following:\n",
    "\n",
    "   1. Optional: the **eliza_language.py** for the adapted Eliza \n",
    "   2. The notebook to create a Bow combining MELD and Tweets\n",
    "   3. This notebook where you:\n",
    "       1. load the emotional conversation with the gold labels, \n",
    "       2. loaded and applied the 4 classifiers (or 5 if VADER is included)\n",
    "       3. added the classifier output to the pandas frame and save the result in a CSV file\n",
    "       3. aggregated the human gold and system labels\n",
    "       4. generated the classification report and the confusion matrix for Ekman (and possibly for sentiment)\n",
    "   4. A CSV file containing the conversation with the gold and \n",
    "   5. A PDF report of max 5 pages (if you included VADER 6 pages) in which you describein three sections:\n",
    "       1. what you have done and why: be explicit about changes you made e.g. to Eliza or training on MELD+Tweets\n",
    "       2. report on the results: use a single table for recall, precision and f-score and put confusion matrixes in the appendix.\n",
    "       3. have a discussion on the results and how to improve the classifiers (see above)\n",
    "\n",
    "If any of 2,3,4,5 is missing in the zip file, you your submission is not graded. Note that 1. is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Loading the conversation saved on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the notebook **eliza-chat.ipynb**, you can create a conversation with Eliza and save it to disk. For this final assignment, we ask each group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello Piek. How are you feeling today?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I am sad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you feel about being sad?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How do you feel when you say that?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                               utterance speaker  \\\n",
       "0             0           0  Hello Piek. How are you feeling today?   Eliza   \n",
       "1             1           1                                I am sad    Piek   \n",
       "2             2           2        How do you feel about being sad?   Eliza   \n",
       "3             3           3                                     Bad    Piek   \n",
       "4             4           4      How do you feel when you say that?   Eliza   \n",
       "\n",
       "   turn_id     Gold  \n",
       "0        1  neutral  \n",
       "1        1  sadness  \n",
       "2        1  neutral  \n",
       "3        1  sadness  \n",
       "4        1  neutral  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'my_emotional_conversation.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. BERT Finetuned for emotion detection with GO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the language model BERT that is finetuned for emotion detection using the *go_emotions* data set. Go_emotions has 28 nuanced emotion labels including neutral, so many more than the basic Ekman emotion that we have seen before. \n",
    "\n",
    "We will define a *sentiment-analysis* pipeline and load the BERT model that was finetuned to classify sentences with the 28 GO_EMOTION labels. It will return a score for all the labels when we set the parameter *return_all_scores* to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\" \n",
    "emotion = pipeline('sentiment-analysis', \n",
    "                    model=model_name, return_all_scores=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instance *emotion* of a transformer pipeline in analogy of an sentiment analysis classification task that we can apply to any utterance. The pipeline will use the tokenizer of the finetuned model and feed the sentence representation to the classifier as a sequence of contextualized token representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying emotion classification to Eliza conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we will apply the GO_EMOTION classifier *emotion* to the conversation loaded in a Pandas frame. We will also map the GO_EMOTIONS to the 6 basic Ekman emotion and to neutral as well as to sentiment values. For the mappings, we defined a few simple utility functions in **lab5_util.py** . We also define a sort function to list the emotions from the highest score down. We first need to import these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab5_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_emotions = []\n",
    "sentiment_scores = []\n",
    "ekman_emotions = []\n",
    "ekman_scores = []\n",
    "go_emotions = []\n",
    "go_scores = []\n",
    "\n",
    "for index, utterance in enumerate(df['utterance']):\n",
    "    emotion_labels = emotion(utterance)\n",
    "    sorted_emotion_labels = util.sort_predictions(emotion_labels[0])\n",
    "    go_emotions.append(sorted_emotion_labels[0]['label'])\n",
    "    go_scores.append(sorted_emotion_labels[0]['score'])\n",
    "\n",
    "    ekman_labels = util.get_averaged_mapped_scores(util.ekman_map, emotion_labels)\n",
    "    ekman_emotions.append(ekman_labels[0]['label'])\n",
    "    ekman_scores.append(ekman_labels[0]['score'])\n",
    "\n",
    "    sentiment_labels = util.get_averaged_mapped_scores(util.sentiment_map, emotion_labels)\n",
    "    sentiment_emotions.append(sentiment_labels[0]['label'])\n",
    "    sentiment_scores.append(sentiment_labels[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected the GO output in separate lists for each utterance. We can now add the output to th pandas frame as separate columns, assuming that the values correspond to the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Go_Sentiment</th>\n",
       "      <th>Go_SentimentScore</th>\n",
       "      <th>Go_Ekman</th>\n",
       "      <th>Go_EkmanScore</th>\n",
       "      <th>Go</th>\n",
       "      <th>GoScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello Piek. How are you feeling today?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.126107</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.287125</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>0.330824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I am sad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.084571</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.181961</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.843814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you feel about being sad?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.115115</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.344749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Piek</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.064023</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.200429</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.200429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How do you feel when you say that?</td>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.173038</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.233936</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>0.585612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                               utterance speaker  \\\n",
       "0             0           0  Hello Piek. How are you feeling today?   Eliza   \n",
       "1             1           1                                I am sad    Piek   \n",
       "2             2           2        How do you feel about being sad?   Eliza   \n",
       "3             3           3                                     Bad    Piek   \n",
       "4             4           4      How do you feel when you say that?   Eliza   \n",
       "\n",
       "   turn_id     Gold Go_Sentiment  Go_SentimentScore Go_Ekman  Go_EkmanScore  \\\n",
       "0        1  neutral    ambiguous           0.126107  neutral       0.287125   \n",
       "1        1  sadness     negative           0.084571  sadness       0.181961   \n",
       "2        1  neutral    ambiguous           0.077716  neutral       0.115115   \n",
       "3        1  sadness     negative           0.064023  neutral       0.200429   \n",
       "4        1  neutral    ambiguous           0.173038  neutral       0.233936   \n",
       "\n",
       "          Go   GoScore  \n",
       "0  curiosity  0.330824  \n",
       "1    sadness  0.843814  \n",
       "2    sadness  0.344749  \n",
       "3    neutral  0.200429  \n",
       "4  curiosity  0.585612  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Go_Sentiment']=sentiment_emotions\n",
    "df['Go_SentimentScore']=sentiment_scores\n",
    "df['Go_Ekman']=ekman_emotions\n",
    "df['Go_EkmanScore']=ekman_scores\n",
    "df['Go']=go_emotions\n",
    "df['GoScore']=go_scores\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and apply the BoW classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO LOAD THE 3 BOW SVM CLASSIFIERS FROM DISK AND TO APPLY THESE TO THE UTTERANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE ADD THE OUTPUT TO THE PANDAS DATA FRAME AS WAS DONE FOR THE GO EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL BONUS: HERE COMES THE CODE TO APPLY VADER TO THE UTTERANCES AND ADD IT THE PANDAS DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE FINAL PANDAS FRAME TO A CSV FILE FOR YOUR SUBMISSION\n",
    "file = \"conversation_with_emotion.csv\"\n",
    "df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE COMES THE CODE TO GENERATE THE CLASSIFICATION REPORT AND THE CONFUSION MATRIX FOR EKMAN EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL BONUS: HERE COMES THE CODE TO TO GENERATE THE CLASSIFICATION REPORT AND THE CONFUSION MATRIX FOR SENTIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
