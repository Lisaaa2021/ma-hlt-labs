{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building sentiment classification using SimpleTransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ThilinaRajapakse/simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Unfortunately, the frustration of being Dr. Go...      0\n",
      "1  Been going to Dr. Goldberg for over 10 years. ...      1\n",
      "2  I don't know what Dr. Goldberg was like before...      0\n",
      "3  I'm writing this review to give you a heads up...      0\n",
      "4  All the food is great here. But the best thing...      1\n",
      "                                                text  label\n",
      "0  Contrary to other reviews, I have zero complai...      1\n",
      "1  Last summer I had an appointment to get new ti...      0\n",
      "2  Friendly staff, same starbucks fair you get an...      1\n",
      "3  The food is good. Unfortunately the service is...      0\n",
      "4  Even when we didn't have a car Filene's Baseme...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "prefix = '/Users/piek/Desktop/ONDERWIJS/data/sentiment/yelp_review_polarity_csv/'\n",
    "\n",
    "train_df = pd.read_csv(prefix + 'train.csv', header=None)\n",
    "train_df.head()\n",
    "\n",
    "eval_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
    "eval_df.head()\n",
    "\n",
    "train_df[0] = (train_df[0] == 2).astype(int)\n",
    "eval_df[0] = (eval_df[0] == 2).astype(int)\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "    'text': train_df[1].replace(r'\\n', ' ', regex=True),\n",
    "    'label':train_df[0]\n",
    "})\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "eval_df = pd.DataFrame({\n",
    "    'text': eval_df[1].replace(r'\\n', ' ', regex=True),\n",
    "    'label':eval_df[0]\n",
    "})\n",
    "\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelArgs' from 'simpletransformers.classification' (/Users/piek/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/simpletransformers/classification/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-65d85a17419e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassificationArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ModelArgs' from 'simpletransformers.classification' (/Users/piek/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/simpletransformers/classification/__init__.py)"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional model configuration\n",
    "#https://github.com/ThilinaRajapakse/simpletransformers/blob/3d3ce91539d628917c08406582295fbf149e185e/simpletransformers/config/model_args.py#L126\n",
    "from simpletransformers.classification import ClassificationArgs\n",
    "model_args = ClassificationArgs(num_train_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47e24d1b7a6404db0918f0ccd350088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074f5b4e1328406d8f48ba329781c984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e518343d703741d6ab57dbff24ebff3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:390: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76daec451f194b8293d039c64a71865b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89153a89e0894deb84c59b54d0572044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cad436759d49dfbfa7a8062b613853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "/Users/piek/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:969: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769c5abb868d47508dd5444f50a826d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ed724d4cae433b87e3201200ebfc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/4750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "# Load a TransformerModel\n",
    "model = ClassificationModel('roberta', 'roberta-base', use_cuda=False)\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5e79ef7b8d41faa856fe47164a67ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e353180d6044d2ea792ef68ec9539f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] This is great.\n",
      "[[-0.01206429 -0.02462326]\n",
      " [-0.01206429 -0.02462329]] This horrible\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"Food is great.\", \"Food is horrible\", \"The food is awful\"]\n",
    "predictions = model.predict(to_predict)\n",
    "for prediction, text in zip(predictions, to_predict):\n",
    "    print(prediction, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0]),\n",
       " array([[-0.01206429, -0.02462326],\n",
       "        [-0.01206429, -0.02462329]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from disk and using again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "loaded_model = ClassificationModel(\n",
    "    \"roberta\", \"outputs/checkpoint-70000-epoch-1\",  use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da21ac5bc71c45198d1a5f4ed2dea633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b208c4eee7e0467f98584321634e32b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] Food is great.\n",
      "[[-0.01206429 -0.02462327]\n",
      " [-0.0120643  -0.02462329]\n",
      " [-0.01206432 -0.0246233 ]] Food is horrible\n"
     ]
    }
   ],
   "source": [
    "to_predict = [\"Food is great.\", \"Food is horrible\", \"The food is awful\"]\n",
    "predictions = loaded_model.predict(to_predict)\n",
    "for prediction, text in zip(predictions, to_predict):\n",
    "    print(prediction, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b17cd147474790a911e72e2b0009f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0013ab2d84cf4e9692969d58f053b1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], array([[-0.01206432, -0.02462327],\n",
      "       [-0.01206431, -0.0246233 ],\n",
      "       [-0.0120643 , -0.02462329],\n",
      "       [-0.01206431, -0.02462328],\n",
      "       [-0.0120643 , -0.02462327],\n",
      "       [-0.01206431, -0.02462329],\n",
      "       [-0.01206429, -0.02462326],\n",
      "       [-0.01206429, -0.02462326],\n",
      "       [-0.01206428, -0.02462326],\n",
      "       [-0.01206431, -0.02462327],\n",
      "       [-0.0120643 , -0.02462327],\n",
      "       [-0.01206431, -0.02462327],\n",
      "       [-0.01206431, -0.02462328],\n",
      "       [-0.01206431, -0.02462327],\n",
      "       [-0.01206431, -0.02462328],\n",
      "       [-0.01206429, -0.02462326],\n",
      "       [-0.01206432, -0.02462328],\n",
      "       [-0.01206431, -0.02462328],\n",
      "       [-0.0120643 , -0.02462327],\n",
      "       [-0.01206431, -0.0246233 ],\n",
      "       [-0.0120643 , -0.02462327],\n",
      "       [-0.01206431, -0.02462328],\n",
      "       [-0.01206429, -0.02462326],\n",
      "       [-0.01206429, -0.02462326],\n",
      "       [-0.01206429, -0.02462327],\n",
      "       [-0.01206429, -0.02462327],\n",
      "       [-0.0120643 , -0.02462327]]))\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(\"All the food is great here.\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "roberta_model = ClassificationModel(\n",
    "    \"roberta\", \"roberta-base\",  use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efd925d3a0b4e1a8a97e99df2332a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a17f23025c4e2b9ff03071728b513e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0]), array([[ 0.09102641, -0.09072606],\n",
      "       [ 0.09262424, -0.09055115],\n",
      "       [ 0.09262431, -0.09055118],\n",
      "       [ 0.08888561, -0.09008861],\n",
      "       [ 0.0946205 , -0.08819972],\n",
      "       [ 0.09009331, -0.09138299],\n",
      "       [ 0.0910597 , -0.09036586],\n",
      "       [ 0.08888561, -0.09008862],\n",
      "       [ 0.09207091, -0.09090179],\n",
      "       [ 0.09286372, -0.09169543],\n",
      "       [ 0.09286369, -0.09169546],\n",
      "       [ 0.09093146, -0.08996344],\n",
      "       [ 0.08888561, -0.09008856],\n",
      "       [ 0.09075122, -0.09047451],\n",
      "       [ 0.09014203, -0.09058407],\n",
      "       [ 0.08888561, -0.09008862],\n",
      "       [ 0.09290265, -0.09378266],\n",
      "       [ 0.08996627, -0.09220961],\n",
      "       [ 0.09105973, -0.0903659 ],\n",
      "       [ 0.09087743, -0.0927995 ],\n",
      "       [ 0.0946205 , -0.08819972],\n",
      "       [ 0.08888561, -0.09008861],\n",
      "       [ 0.09009334, -0.09138294],\n",
      "       [ 0.0910597 , -0.09036589],\n",
      "       [ 0.08996624, -0.09220962],\n",
      "       [ 0.09105968, -0.09036589],\n",
      "       [ 0.09134918, -0.08956723]]))\n"
     ]
    }
   ],
   "source": [
    "predictions = roberta_model.predict(\"All the food is great here.\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
