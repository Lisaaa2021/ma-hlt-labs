{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use fine-tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer models such as BERT and RoBERTa can easily be fine-tuned for downstream tasks. The Huggingface model hub lists many of these models trained for specific tasks. You can download such a model and use it to perform specific NLP tasks. Here we show two examples of fine-tuned models for xlm-roberta. Because the language model is cross-lingual, also the fine-tuned model works for all the 100 languages that xlm-roberta models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search on the Model Hub of Huggingface for a fine-tuned model for sentiment classification, e.g.:\n",
    "\n",
    "https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3aa93b763d14381a5068e93aaaba877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2455ccf64b004f3d88e1bce5854ebd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759a3d8630c74ce4be7957fdb289d693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80d6b6654c3442b830d9458498d407f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Negative', 'score': 0.9273000359535217}]\n",
      "[{'label': 'Negative', 'score': 0.8501133322715759}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_task(\"What an awful movie!\"))\n",
    "print(sentiment_task(\"Wat een waardeloze film!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6547bb3d8ca464eb9b73f1a37453527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/980 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90537ebde4749609aa63bf622cd760a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63a9f66543b43f79ad019fdff84e16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2908fb596841f59585158b947d5ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/211 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a90eb963e444498cc3a514a2a829ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': '▁Na', 'score': 0.9998415112495422, 'entity': 'B-PER', 'index': 1, 'start': 0, 'end': 2}, {'word': 'der', 'score': 0.880562961101532, 'entity': 'I-PER', 'index': 2, 'start': 2, 'end': 5}, {'word': '▁Jo', 'score': 0.9998159408569336, 'entity': 'I-PER', 'index': 3, 'start': 5, 'end': 8}, {'word': 'kha', 'score': 0.9998022317886353, 'entity': 'I-PER', 'index': 4, 'start': 8, 'end': 11}, {'word': 'dar', 'score': 0.9997529983520508, 'entity': 'I-PER', 'index': 5, 'start': 11, 'end': 14}, {'word': '▁Syria', 'score': 0.9996248483657837, 'entity': 'B-LOC', 'index': 8, 'start': 24, 'end': 30}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Davlan/xlm-roberta-base-ner-hrl\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Davlan/xlm-roberta-base-ner-hrl\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute.\"\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': '▁Mark', 'score': 0.9998753070831299, 'entity': 'B-PER', 'index': 1, 'start': 0, 'end': 4}, {'word': '▁Rut', 'score': 0.9998551607131958, 'entity': 'I-PER', 'index': 2, 'start': 4, 'end': 8}, {'word': 'te', 'score': 0.9998762011528015, 'entity': 'I-PER', 'index': 3, 'start': 8, 'end': 10}, {'word': '▁VVD', 'score': 0.9991850256919861, 'entity': 'B-ORG', 'index': 9, 'start': 29, 'end': 33}, {'word': '▁Google', 'score': 0.999866247177124, 'entity': 'B-ORG', 'index': 13, 'start': 54, 'end': 61}, {'word': '▁Facebook', 'score': 0.9998590350151062, 'entity': 'B-ORG', 'index': 15, 'start': 62, 'end': 71}, {'word': '▁Apple', 'score': 0.999846875667572, 'entity': 'B-ORG', 'index': 17, 'start': 74, 'end': 80}]\n"
     ]
    }
   ],
   "source": [
    "example = \"Mark Rutte kondigt aan dat de VVD tech bedrijven zoals Google, Facebook en Apple zwaarder gaat belasten.\"\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
