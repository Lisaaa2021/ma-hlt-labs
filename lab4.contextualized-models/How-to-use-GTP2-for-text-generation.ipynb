{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886a9b375f29463eb391132143a057c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a7f7000bbe4182926ffd06f4243465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d548c5d0cf2f4c41987343e79ee8eac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033589e36c694750b03f82fee5821427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe98d703366745f0811ffc36cfb6e899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from simpletransformers.language_generation import (\n",
    "    LanguageGenerationModel,\n",
    ")\n",
    "\n",
    "model = LanguageGenerationModel(\n",
    "    \"gpt2\", \"gpt2\", use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Model prompt >>>  Hi how are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hi how are you? Well, you're good… you're kind of like that old school big brother. And there's\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 for other languages than English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a GPT model from scratch is costly. You not only need a lot of data but "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/wietsedv/gpt2-recycle\n",
    "\n",
    "https://aclanthology.org/2021.findings-acl.74.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Was ik maar een kind geweest?'\\nIk keek haar in de ogen. 'Wat is er met je gebeurd? Ik heb mijn ouders verloren.'\\nZe schudde heftig haar hoofd. 'Nee, we hadden het niet kunnen hebben gedaan,' zei ze terwijl ze naar achteren liep om te voorkomen dat zijn gezicht zou gaan bevriezen. 'Je hebt geen idee waar jij mee bezig was en wat hij ervan had weerhouden me zo snel mogelijk hiernaartoe te komen...'\\n'We wilden allebei weten wie die vent achter ons aan\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "\n",
    "dutchGpt2pipe = pipeline(\"text-generation\", model=\"GroNLP/gpt2-small-dutch\")\n",
    "print(dutchGpt2pipe('Was ik maar een klein'))\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/gpt2-small-dutch\")\n",
    "#model = AutoModel.from_pretrained(\"GroNLP/gpt2-small-dutch\")  # PyTorch\n",
    "#model = TFAutoModel.from_pretrained(\"GroNLP/gpt2-small-dutch\")  # Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Was ik maar een klein kind.\\'\\nHij knikte. Hij had haar niet verteld wat ze moest doen om hem te beschermen, en er was geen bewijs dat hij ooit in de buurt van zijn huis zou blijven rondhangen. \\'En dan is het nog steeds zo moeilijk als je me wilt vragen waarom jij dit allemaal hebt gedaan?\\'\\nHaar ogen vulden zich met tranen omdat ze niets kon zeggen over die vreselijke waarheid. De woorden waren al bijna twee weken uit hun hoofd geweest: \"Je kunt mijn leven ruïneren'}]\n"
     ]
    }
   ],
   "source": [
    "print(dutchGpt2pipe('Was ik maar een klein'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5711150ad2a64e59bde43dfe1109e5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/959 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbf2cfecd894e519b020f8cf2829907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/448M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53df12b54c8480e96e7dd032870fa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/487k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceebb6e8d9dc409da0d913fcb6ca2e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/287k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986bccb973a84d2688a4bb2a964ec9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8235a48c0624abeadd1dbd6b60da333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Uno bambino picologizzato che non riesce mai ad uscire dal recinto per andare via.\\n\\nIl romanzo è stato tratto da \"La Stampa\" in collaborazione con il Centro di Documentazione Giuridica dell\\'Istituto Magistrale (CSA), e pubblicato dalla Mondadori nel novembre dello stesso anno, mentre l\\'edizione originale era stata pubblicata come un libro d\\'esordio sul sito web www.centrodigiustizia.it; la versione integrale si basa su una ricerca realizzata dall\\'Università degli Studi di Roma'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "italianGpt2pipe = pipeline(\"text-generation\", model=\"GroNLP/gpt2-small-italian\")\n",
    "\n",
    "print(italianGpt2pipe('Uno bambino picolo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
