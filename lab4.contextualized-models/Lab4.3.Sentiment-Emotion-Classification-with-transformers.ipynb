{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3.4 Sentiment and Emotion Classification using transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how you can use a transformer model that is fine-tuned for sentiment analysis. Fine-tuned transformer models are published regularly on the huggingface platform: https://huggingface.co/models\n",
    "\n",
    "These models are very big (Gigabytes) and require a computer with sufficient memory to load. Furthermore, loading these models takes some time as well. It is also possible to copy such a model to your disk and to load the local copy. Still a substantial memory is needed to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP pipelines for transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface transfomers provides an option to create an **pipeline** to perform a NLP task with a pretrained model: \n",
    "\n",
    "\"The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering.\"\n",
    "\n",
    "More information can be found here: \n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "The pipelines are abstractions from specific task such as sentiment-analysis and entity recognition. In the case of sentiment-analysis, the complete sentence representation of the model is taken as the input and classified for the the defined labels. In the case of entity recognition, each token in a sentence is classified separately in a sequence, i.e. a sequence classification task. Whereas a finetuned model can be used for a task depends on the way it was fine tuned with labeled data. \n",
    "\n",
    "We will use the pipeline module to load a fine-tuned model to perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a transformer model 'distilbert-base-uncased-finetuned-sst-2-english' that is fine-tuned for binary classification from the Hugging face repository:\n",
    "\n",
    "https://huggingface.co/models\n",
    "\n",
    "We need to load the model for the sequence classifcation and the tokenizer to convert the sentences into tokens according to the vocabulary of the model.\n",
    "\n",
    "Loading the model takes some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an English fine-tuned transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentenglish = pipeline(\"sentiment-analysis\", \n",
    "                            model=\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                            tokenizer=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instantiation of a pipeline that can tokenize any sentence, obtain a sententence embedding from the transformer language model and perform the **sentiment-analysis** task. Let's try it out on an example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pos_en = \"Nice hotel and the service is great\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998814463615417}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentenglish(sentence_pos_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_neg_en = \"The rooms are dirty and the wifi does not work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997869729995728}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentenglish(sentence_neg_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easy and seems to work very well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Dutch fine-tuned transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a fine-tuned Dutch model for Dutch sentiment analysis by creating another pipeline. Again loading this model takes some time. Also note that after loading, both models are loaded in memory. So if you have issues loading, you may want to start over and try again just with the Dutch pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentdutch = pipeline(\"sentiment-analysis\", \n",
    "                          model=\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\", \n",
    "                          tokenizer=\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test it on two similar Dutch sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pos_nl=\"Mooi hotel en de service is geweldig\"\n",
    "sentence_neg_nl=\"De kamers zijn smerig en de wifi doet het niet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos', 'score': 0.9999955892562866}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentdutch(sentence_pos_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg', 'score': 0.6675440073013306}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentdutch(sentence_neg_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine too although the score for negative in the second example is much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BERT Finetuned for emotion detection with GO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the language model BERT that is finetuned for emotion detection using the *go_emotions* data set. Go_emotions has 28 nuanced emotion labels including neutral, so many more than the basic Ekman emotion that we have seen before.\n",
    "\n",
    "https://github.com/google-research/google-research/tree/master/goemotions\n",
    "\n",
    "```\n",
    "LABELS = [\n",
    "    'admiration',\n",
    "    'amusement',\n",
    "    'anger',\n",
    "    'annoyance',\n",
    "    'approval',\n",
    "    'caring',\n",
    "    'confusion',\n",
    "    'curiosity',\n",
    "    'desire',\n",
    "    'disappointment',\n",
    "    'disapproval',\n",
    "    'disgust',\n",
    "    'embarrassment',\n",
    "    'excitement',\n",
    "    'fear',\n",
    "    'gratitude',\n",
    "    'grief',\n",
    "    'joy',\n",
    "    'love',\n",
    "    'nervousness',\n",
    "    'optimism',\n",
    "    'pride',\n",
    "    'realization',\n",
    "    'relief',\n",
    "    'remorse',\n",
    "    'sadness',\n",
    "    'surprise',\n",
    "    'neutral',\n",
    "]```\n",
    "\n",
    "We will define a *sentiment-analysis* pipeline and load the BERT model that was finetuned to classify sentences with the 28 GO_EMOTION labels. It will return a score for all the labels when we set the parameter *return_all_scores* to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\" \n",
    "emotion_pipeline = pipeline('sentiment-analysis', \n",
    "                    model=model_name, return_all_scores=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instance *emotion_pipeline* of a transformer pipeline in analogy of an sentiment analysis classification task that we can apply to any utterance. The pipeline will use the tokenizer of the finetuned model and feed the sentence representation to the classifier as a sequence of contextualized token representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = emotion_pipeline(\"Thanks for using it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'admiration', 'score': 0.0007500764913856983}\n",
      "{'label': 'amusement', 'score': 0.00011047106818296015}\n",
      "{'label': 'anger', 'score': 9.69245083979331e-05}\n",
      "{'label': 'annoyance', 'score': 0.0002597433340270072}\n",
      "{'label': 'approval', 'score': 0.0011426000855863094}\n",
      "{'label': 'caring', 'score': 0.00030970710213296115}\n",
      "{'label': 'confusion', 'score': 0.00014959769032429904}\n",
      "{'label': 'curiosity', 'score': 0.00015838834224268794}\n",
      "{'label': 'desire', 'score': 0.0001385686337016523}\n",
      "{'label': 'disappointment', 'score': 0.00016352151578757912}\n",
      "{'label': 'disapproval', 'score': 0.00020030527957715094}\n",
      "{'label': 'disgust', 'score': 5.9684312873287126e-05}\n",
      "{'label': 'embarrassment', 'score': 5.588319982052781e-05}\n",
      "{'label': 'excitement', 'score': 0.00018467492191120982}\n",
      "{'label': 'fear', 'score': 5.239497113507241e-05}\n",
      "{'label': 'gratitude', 'score': 0.9934592247009277}\n",
      "{'label': 'grief', 'score': 2.022587250394281e-05}\n",
      "{'label': 'joy', 'score': 0.0003203642263542861}\n",
      "{'label': 'love', 'score': 0.00014530749467667192}\n",
      "{'label': 'nervousness', 'score': 3.977019150624983e-05}\n",
      "{'label': 'optimism', 'score': 0.0003828597837127745}\n",
      "{'label': 'pride', 'score': 8.253977284766734e-05}\n",
      "{'label': 'realization', 'score': 0.0004446822276804596}\n",
      "{'label': 'relief', 'score': 0.00020675198175013065}\n",
      "{'label': 'remorse', 'score': 5.820744263473898e-05}\n",
      "{'label': 'sadness', 'score': 9.699811926111579e-05}\n",
      "{'label': 'surprise', 'score': 0.00010775569535326213}\n",
      "{'label': 'neutral', 'score': 0.0008028814336284995}\n"
     ]
    }
   ],
   "source": [
    "for result in emotion_labels[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GO emotions are a lot more nuanced than the Ekman emotions. They are based on a diverse range of emotion data and not just facial expression. Nevertheless it is possible to mape the more specific emotions to Ekman's more basic ones and even to sentiments. The next specifications given on the original Github of goemotions just do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mapping GO_Emotions to sentiment values\n",
    "sentiment_map={\n",
    "\"positive\": [\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\", \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"],\n",
    "\"negative\": [\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\", \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"],\n",
    "\"ambiguous\": [\"realization\", \"surprise\", \"curiosity\", \"confusion\"]\n",
    "}\n",
    "\n",
    "### Mapping GO_Emotions to Ekman values\n",
    "ekman_map={\n",
    "\"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "\"disgust\": [\"disgust\"],\n",
    "\"fear\": [\"fear\", \"nervousness\"],\n",
    "\"joy\": [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",  \"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"],\n",
    "\"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
    "\"surprise\": [\"surprise\", \"realization\", \"confusion\", \"curiosity\"],\n",
    "\"neutral\": [\"neutral\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a few simple auxiliary functions that can make the translation from the GO emotions to Ekman or sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sort a list of results in JSON format by the value of the score element\n",
    "def sort_predictions(predictions):\n",
    "    return sorted(predictions, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "\n",
    "### Use a mapping to get a dictionary of the mapped GO_emotion scores\n",
    "def get_mapped_scores(emotion_map, go_emotion_scores):\n",
    "    mapped_scores = {}\n",
    "\n",
    "    for prediction in go_emotion_scores[0]:\n",
    "        go_emotion=prediction['label']\n",
    "        for key in emotion_map:\n",
    "            if go_emotion in emotion_map[key]:\n",
    "                if not key in mapped_scores:\n",
    "                    mapped_scores[key]= [prediction['score']]\n",
    "                else:\n",
    "                    mapped_scores[key].append(prediction['score'])\n",
    "    return mapped_scores\n",
    "\n",
    "### Get the averaged score for an emotion or sentiment from the GO_emotion scores mapped according to the emotion_map\n",
    "def get_averaged_mapped_scores(emotion_map, go_emotion_scores):\n",
    "    averaged_mapped_scores = []\n",
    "    mapped_scores = get_mapped_scores(emotion_map, go_emotion_scores)\n",
    "    for emotion in mapped_scores:\n",
    "        lst = mapped_scores[emotion]\n",
    "        averaged_score= sum(lst)/len(lst)\n",
    "        averaged_mapped_scores.append({'label':emotion, 'score':averaged_score})\n",
    "    return sort_predictions(averaged_mapped_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these function, we can print the averaged Ekman and the averaged sentiment score for any GO emotion classifition result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'joy', 'score': 0.08310276218859751}\n",
      "{'label': 'neutral', 'score': 0.0008028814336284995}\n",
      "{'label': 'surprise', 'score': 0.00021510598890017718}\n",
      "{'label': 'anger', 'score': 0.00018565770733403042}\n",
      "{'label': 'sadness', 'score': 7.89672300015809e-05}\n",
      "{'label': 'disgust', 'score': 5.9684312873287126e-05}\n",
      "{'label': 'fear', 'score': 4.608258132066112e-05}\n"
     ]
    }
   ],
   "source": [
    "ekman_labels = get_averaged_mapped_scores(ekman_map, emotion_labels)\n",
    "for ekman in ekman_labels:\n",
    "    print(ekman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'positive', 'score': 0.08310276218859751}\n",
      "{'label': 'ambiguous', 'score': 0.00021510598890017718}\n",
      "{'label': 'negative', 'score': 0.00010033261341132774}\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores = get_averaged_mapped_scores(sentiment_map, emotion_labels)\n",
    "for sentiment in sentiment_scores:\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
