{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3.4 Sentiment Classification using transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how you can use a transformer model that is fine-tuned for sentiment analysis. Fine-tuned transformer models are published regularly on the huggingface platform: https://huggingface.co/models\n",
    "\n",
    "These models are very big (Gigabytes) and require a computer with sufficient memory to load. Furthermore, loading these models takes some time as well. It is also possible to copy such a model to your disk and to load the local copy. Still a substantial memory is needed to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface transfomers provides an option to create an **pipeline** to perform a NLP task with a pretrained model: \n",
    "\n",
    "\"The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering.\"\n",
    "\n",
    "More information can be found here: https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html\n",
    "\n",
    "We will use the pipeline module to load a fine-tuned model to perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a transformer model 'distilbert-base-uncased-finetuned-sst-2-english' that is fine-tuned for binary classification from the Hugging face repository:\n",
    "\n",
    "https://huggingface.co/models\n",
    "\n",
    "We need to load the model for the sequence classifcation and the tokenizer to convert the sentences into tokens according to the vocabulary of the model.\n",
    "\n",
    "Loading the model takes some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an English fine-tuned transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentenglish = pipeline(\"sentiment-analysis\", \n",
    "                            model=\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                            tokenizer=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instantiation of a pipeline that can tokenize any sentence, obtain a sententence embedding from the transformer language model and perform the **sentiment-analysis** task. Let's try it out on an example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pos_en = \"Nice hotel and the service is great\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998814463615417}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentenglish(sentence_pos_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_neg_en = \"The rooms are dirty and the wifi does not work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997869729995728}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentenglish(sentence_neg_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easy and seems to work very well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Dutch fine-tuned transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a fine-tuned Dutch model for Dutch sentiment analysis by creating another pipeline. Again loading this model takes some time. Also note that after loading, both models are loaded in memory. So if you have issues loading, you may want to start over and try again just with the Dutch pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentdutch = pipeline(\"sentiment-analysis\", \n",
    "                          model=\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\", \n",
    "                          tokenizer=\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test it on two similar Dutch sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pos_nl=\"Mooi hotel en de service is geweldig\"\n",
    "sentence_neg_nl=\"De kamers zijn smerig en de wifi doet het niet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos', 'score': 0.9999955892562866}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentdutch(sentence_pos_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg', 'score': 0.6675440073013306}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentdutch(sentence_neg_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine too although the score for negative in the second example is much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BERT Finetuned for emotion detection with GO dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the language model BERT that is finetuned for emotion detection using the *go_emotions* data set. Go_emotions has 28 nuanced emotion labels including neutral, so many more than the basic Ekman emotion that we have seen before. \n",
    "\n",
    "We will load the finetuned model from the huggingface.co platform as part of a so-called transformer *pipeline*. Pipelines are predefined NLP tasks that deploy a trained model for a specific type of task. See the website for an overview of the different pipelines defined by huggingface.co:\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "The pipelines are abstractions from specific task such as sentiment-analysis and entity recognition. In the case of sentiment-analysis, the complete sentence representation of the model is taken as the input and classified for the the defined labels. In the case of entity recognition, each token in a sentence is classified separately in a sequence, i.e. a sequence classification task. Whereas a finetuned model can be used for a task depends on the way it was fine tuned with labeled data. \n",
    "\n",
    "We will define a *sentiment-analysis* pipeline and load the BERT model that was finetuned to classify sentences with the 28 GO_EMOTION labels. It will return a score for all the labels when we set the parameter *return_all_scores* to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\" \n",
    "emotion_pipeline = pipeline('sentiment-analysis', \n",
    "                    model=model_name, return_all_scores=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created an instance *emotion* of a transformer pipeline in analogy of an sentiment analysis classification task that we can apply to any utterance. The pipeline will use the tokenizer of the finetuned model and feed the sentence representation to the classifier as a sequence of contextualized token representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'admiration', 'score': 0.0007500764913856983}\n",
      "{'label': 'amusement', 'score': 0.00011047106818296015}\n",
      "{'label': 'anger', 'score': 9.69245083979331e-05}\n",
      "{'label': 'annoyance', 'score': 0.0002597433340270072}\n",
      "{'label': 'approval', 'score': 0.0011426000855863094}\n",
      "{'label': 'caring', 'score': 0.00030970710213296115}\n",
      "{'label': 'confusion', 'score': 0.00014959769032429904}\n",
      "{'label': 'curiosity', 'score': 0.00015838834224268794}\n",
      "{'label': 'desire', 'score': 0.0001385686337016523}\n",
      "{'label': 'disappointment', 'score': 0.00016352151578757912}\n",
      "{'label': 'disapproval', 'score': 0.00020030527957715094}\n",
      "{'label': 'disgust', 'score': 5.9684312873287126e-05}\n",
      "{'label': 'embarrassment', 'score': 5.588319982052781e-05}\n",
      "{'label': 'excitement', 'score': 0.00018467492191120982}\n",
      "{'label': 'fear', 'score': 5.239497113507241e-05}\n",
      "{'label': 'gratitude', 'score': 0.9934592247009277}\n",
      "{'label': 'grief', 'score': 2.022587250394281e-05}\n",
      "{'label': 'joy', 'score': 0.0003203642263542861}\n",
      "{'label': 'love', 'score': 0.00014530749467667192}\n",
      "{'label': 'nervousness', 'score': 3.977019150624983e-05}\n",
      "{'label': 'optimism', 'score': 0.0003828597837127745}\n",
      "{'label': 'pride', 'score': 8.253977284766734e-05}\n",
      "{'label': 'realization', 'score': 0.0004446822276804596}\n",
      "{'label': 'relief', 'score': 0.00020675198175013065}\n",
      "{'label': 'remorse', 'score': 5.820744263473898e-05}\n",
      "{'label': 'sadness', 'score': 9.699811926111579e-05}\n",
      "{'label': 'surprise', 'score': 0.00010775569535326213}\n",
      "{'label': 'neutral', 'score': 0.0008028814336284995}\n"
     ]
    }
   ],
   "source": [
    "emotion_labels = emotion_pipeline(\"Thanks for using it.\")\n",
    "for result in emotion_labels[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
